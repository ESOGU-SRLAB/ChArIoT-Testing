"""
    This file contains the decoding function for the transformer model to generate output sequence using greedy algorithm.
"""
import torch

from parameters import DEVICE, EOS_IDX
from masking import generate_square_subsequent_mask


def greedy_decode(model, src, src_mask, max_len, start_symbol):
    """
    function to generate output sequence using greedy algorithm

    Args:
        model: transformer model object to be used for decoding the output sequence from the input sequence
        src: input sequence tensor of shape (1, src_len) where src_len is the length of the input sequence
        src_mask: input sequence mask tensor of shape (1, 1, src_len) where src_len is the length of the input sequence
        max_len: maximum length of the output sequence to be generated by the model
        start_symbol: start symbol index to be used for generating the output sequence by the model

    Returns:
        ys: output sequence tensor of shape (1, max_len) where max_len is the maximum length of the output sequence
    """
    src = src.to(DEVICE)  # send input sequence tensor to device
    src_mask = src_mask.to(DEVICE)  # send input sequence mask tensor to device

    memory = model.encode(src, src_mask)  # encode the input sequence using the model
    ys = (
        torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)
    )  # initialize the output sequence tensor with start symbol index
    for i in range(max_len - 1):  # loop over the maximum length of the output sequence
        memory = memory.to(DEVICE)  # send the encoded input sequence to device
        tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(
            DEVICE
        )  # generate the target mask for the output sequence
        out = model.decode(
            ys, memory, tgt_mask
        )  # decode the output sequence using the model
        out = out.transpose(0, 1)  # transpose the output sequence tensor
        prob = model.generator(
            out[:, -1]
        )  # generate the probability distribution for the last token in the output sequence
        _, next_word = torch.max(
            prob, dim=1
        )  # get the index of the token with maximum probability
        next_word = (
            next_word.item()
        )  # get the index of the token with maximum probability as an integer

        ys = torch.cat(
            [ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0
        )  # append the token index to the output sequence tensor
        if (
            next_word == EOS_IDX
        ):  # if the token index is the end of sequence index, break the loop
            break  # break the loop
    return ys  # return the output sequence tensor
